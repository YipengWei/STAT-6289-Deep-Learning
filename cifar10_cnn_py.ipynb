{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IszFBGHQyIMx"
   },
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SfV895YDvU7J"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHngr4F5yeXV"
   },
   "source": [
    "Load data and set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3R0dBp6rvYek",
    "outputId": "dc424020-e1b9-4076-9c6b-ee9d3d62f994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D16Y9hMByiKX"
   },
   "source": [
    "Generate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "o_J3v0XUveSt"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "    input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygnG_8_EyEyS"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHtKdVCxvlzo",
    "outputId": "91717155-d408-4503-f149-dc6e7d724d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_5233/706324705.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_CNN = model.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 18s 180ms/step - loss: 2.1390 - accuracy: 0.2083 - val_loss: 1.9737 - val_accuracy: 0.3054\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 18s 180ms/step - loss: 1.9446 - accuracy: 0.2939 - val_loss: 1.8027 - val_accuracy: 0.3755\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 18s 184ms/step - loss: 1.8326 - accuracy: 0.3370 - val_loss: 1.7130 - val_accuracy: 0.3996\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 18s 185ms/step - loss: 1.7650 - accuracy: 0.3590 - val_loss: 1.6388 - val_accuracy: 0.4131\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 19s 189ms/step - loss: 1.7140 - accuracy: 0.3796 - val_loss: 1.5898 - val_accuracy: 0.4343\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 19s 189ms/step - loss: 1.6701 - accuracy: 0.3923 - val_loss: 1.5361 - val_accuracy: 0.4531\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 19s 188ms/step - loss: 1.6342 - accuracy: 0.4063 - val_loss: 1.4990 - val_accuracy: 0.4608\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 18s 185ms/step - loss: 1.6047 - accuracy: 0.4170 - val_loss: 1.4551 - val_accuracy: 0.4740\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 18s 185ms/step - loss: 1.5736 - accuracy: 0.4276 - val_loss: 1.5028 - val_accuracy: 0.4618\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 19s 188ms/step - loss: 1.5495 - accuracy: 0.4368 - val_loss: 1.4159 - val_accuracy: 0.4909\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "  print('Not using data augmentation.')\n",
    "  model.fit(x_train, y_train,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      validation_data=(x_test, y_test),\n",
    "      shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "  Fit_CNN = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                  batch_size=batch_size),\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xmliur4x6-m"
   },
   "source": [
    "Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrsrKKTCv46j",
    "outputId": "73b833bf-47c0-4f24-ce44-fa08bba3ea8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /Users/yipengwei/Downloads/saved_models/keras_cifar10_trained_model.h5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yipengwei/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIwudEcwx_XJ"
   },
   "source": [
    "Score trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UO1CDSJwx-nu",
    "outputId": "4953a98e-e084-412e-b534-e788f226b5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 2.0111 - accuracy: 0.2807\n",
      "Test loss: 2.0111401081085205\n",
      "Test accuracy: 0.2806999981403351\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hidden Layer 0\n",
    "'''\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model_hidden_layer_0 = Sequential()\n",
    "model_hidden_layer_0.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "model_hidden_layer_0.add(Dense(num_classes))\n",
    "model_hidden_layer_0.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/220951600.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_hidden_layer_0 = model_hidden_layer_0.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 6s 55ms/step - loss: 2.1649 - accuracy: 0.2094 - val_loss: 2.0472 - val_accuracy: 0.2687\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 6s 55ms/step - loss: 2.0224 - accuracy: 0.2750 - val_loss: 1.9664 - val_accuracy: 0.3050\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 5s 53ms/step - loss: 1.9727 - accuracy: 0.3033 - val_loss: 1.9225 - val_accuracy: 0.3278\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 1.9430 - accuracy: 0.3144 - val_loss: 1.8940 - val_accuracy: 0.3370\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 6s 55ms/step - loss: 1.9224 - accuracy: 0.3235 - val_loss: 1.8752 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 1.9116 - accuracy: 0.3288 - val_loss: 1.8653 - val_accuracy: 0.3521\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 1.9015 - accuracy: 0.3343 - val_loss: 1.8502 - val_accuracy: 0.3554\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 6s 55ms/step - loss: 1.8912 - accuracy: 0.3377 - val_loss: 1.8491 - val_accuracy: 0.3477\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 5s 53ms/step - loss: 1.8840 - accuracy: 0.3413 - val_loss: 1.8417 - val_accuracy: 0.3573\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 1.8798 - accuracy: 0.3422 - val_loss: 1.8396 - val_accuracy: 0.3534\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "model_hidden_layer_0.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model_hidden_layer_0.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_hidden_layer_0 = model_hidden_layer_0.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hidden Layer 1\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model_hidden_layer_1 = Sequential()\n",
    "model_hidden_layer_1.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "model_hidden_layer_1.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model_hidden_layer_1.add(Dropout(0.5))\n",
    "model_hidden_layer_1.add(Dense(num_classes))\n",
    "model_hidden_layer_1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/453467427.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_hidden_layer_1 = model_hidden_layer_1.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 6s 63ms/step - loss: 2.4565 - accuracy: 0.1908 - val_loss: 2.0914 - val_accuracy: 0.2824\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 6s 61ms/step - loss: 2.2010 - accuracy: 0.2460 - val_loss: 1.9767 - val_accuracy: 0.3045\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 6s 60ms/step - loss: 2.1610 - accuracy: 0.2609 - val_loss: 1.9774 - val_accuracy: 0.3022\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 6s 61ms/step - loss: 2.1090 - accuracy: 0.2768 - val_loss: 1.9752 - val_accuracy: 0.3090\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 6s 61ms/step - loss: 2.0884 - accuracy: 0.2830 - val_loss: 2.0735 - val_accuracy: 0.3234\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 6s 61ms/step - loss: 2.0639 - accuracy: 0.2868 - val_loss: 2.0169 - val_accuracy: 0.2711\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 6s 61ms/step - loss: 2.0483 - accuracy: 0.2893 - val_loss: 1.8718 - val_accuracy: 0.3537\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 6s 61ms/step - loss: 2.0373 - accuracy: 0.2950 - val_loss: 1.8691 - val_accuracy: 0.3306\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 6s 62ms/step - loss: 2.0177 - accuracy: 0.3001 - val_loss: 1.8825 - val_accuracy: 0.3196\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 6s 61ms/step - loss: 2.0073 - accuracy: 0.3041 - val_loss: 1.9229 - val_accuracy: 0.3232\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "model_hidden_layer_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model_hidden_layer_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_hidden_layer_1 = model_hidden_layer_1.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hidden Layer 2\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model_hidden_layer_2 = Sequential()\n",
    "model_hidden_layer_2.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "model_hidden_layer_2.add(Dense(512))\n",
    "model_hidden_layer_2.add(Activation('relu'))\n",
    "model_hidden_layer_2.add(Dropout(0.5))\n",
    "model_hidden_layer_2.add(Dense(512))\n",
    "model_hidden_layer_2.add(Activation('relu'))\n",
    "model_hidden_layer_2.add(Dropout(0.5))\n",
    "model_hidden_layer_2.add(Dense(num_classes))\n",
    "model_hidden_layer_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/3875659683.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_hidden_layer_2 = model_hidden_layer_2.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 7s 65ms/step - loss: 2.1518 - accuracy: 0.2080 - val_loss: 1.9600 - val_accuracy: 0.2948\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 7s 64ms/step - loss: 2.0098 - accuracy: 0.2659 - val_loss: 1.8678 - val_accuracy: 0.3514\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 6s 62ms/step - loss: 1.9446 - accuracy: 0.2974 - val_loss: 1.8115 - val_accuracy: 0.3653\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 7s 63ms/step - loss: 1.9078 - accuracy: 0.3139 - val_loss: 1.7493 - val_accuracy: 0.3841\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 7s 64ms/step - loss: 1.8768 - accuracy: 0.3249 - val_loss: 1.7200 - val_accuracy: 0.3993\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 7s 63ms/step - loss: 1.8585 - accuracy: 0.3335 - val_loss: 1.7303 - val_accuracy: 0.3962\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 7s 66ms/step - loss: 1.8319 - accuracy: 0.3419 - val_loss: 1.6762 - val_accuracy: 0.4126\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 7s 63ms/step - loss: 1.8172 - accuracy: 0.3486 - val_loss: 1.6583 - val_accuracy: 0.4288\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 6s 63ms/step - loss: 1.8058 - accuracy: 0.3543 - val_loss: 1.6496 - val_accuracy: 0.4269\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 7s 65ms/step - loss: 1.7894 - accuracy: 0.3620 - val_loss: 1.6647 - val_accuracy: 0.4125\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "model_hidden_layer_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model_hidden_layer_2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_hidden_layer_2 = model_hidden_layer_2.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hidden Layer 3\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model_hidden_layer_3 = Sequential()\n",
    "model_hidden_layer_3.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "model_hidden_layer_3.add(Dense(512))\n",
    "model_hidden_layer_3.add(Activation('relu'))\n",
    "model_hidden_layer_3.add(Dropout(0.5))\n",
    "model_hidden_layer_3.add(Dense(512))\n",
    "model_hidden_layer_3.add(Activation('relu'))\n",
    "model_hidden_layer_3.add(Dropout(0.5))\n",
    "model_hidden_layer_3.add(Dense(512))\n",
    "model_hidden_layer_3.add(Activation('relu'))\n",
    "model_hidden_layer_3.add(Dropout(0.5))\n",
    "model_hidden_layer_3.add(Dense(num_classes))\n",
    "model_hidden_layer_3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/230360576.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_hidden_layer_3 = model_hidden_layer_3.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 7s 67ms/step - loss: 2.6599 - accuracy: 0.1779 - val_loss: 2.1377 - val_accuracy: 0.2508\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 7s 65ms/step - loss: 2.2958 - accuracy: 0.2222 - val_loss: 1.8870 - val_accuracy: 0.3342\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 7s 67ms/step - loss: 2.2178 - accuracy: 0.2361 - val_loss: 1.8699 - val_accuracy: 0.3552\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 7s 68ms/step - loss: 2.1702 - accuracy: 0.2441 - val_loss: 1.8542 - val_accuracy: 0.3554\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 7s 68ms/step - loss: 2.1402 - accuracy: 0.2507 - val_loss: 1.8544 - val_accuracy: 0.3578\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 7s 68ms/step - loss: 2.1187 - accuracy: 0.2579 - val_loss: 1.9114 - val_accuracy: 0.3231\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 7s 66ms/step - loss: 2.1001 - accuracy: 0.2609 - val_loss: 1.8349 - val_accuracy: 0.3495\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 7s 66ms/step - loss: 2.0831 - accuracy: 0.2652 - val_loss: 1.8485 - val_accuracy: 0.3440\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 7s 66ms/step - loss: 2.0638 - accuracy: 0.2707 - val_loss: 1.8249 - val_accuracy: 0.3639\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 2.0534 - accuracy: 0.2725 - val_loss: 1.8639 - val_accuracy: 0.3446\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "model_hidden_layer_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model_hidden_layer_3.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_hidden_layer_3 = model_hidden_layer_3.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hidden Layer 4\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model_hidden_layer_4 = Sequential()\n",
    "model_hidden_layer_4.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "model_hidden_layer_4.add(Dense(512))\n",
    "model_hidden_layer_4.add(Activation('relu'))\n",
    "model_hidden_layer_4.add(Dropout(0.5))\n",
    "model_hidden_layer_4.add(Dense(512))\n",
    "model_hidden_layer_4.add(Activation('relu'))\n",
    "model_hidden_layer_4.add(Dropout(0.5))\n",
    "model_hidden_layer_4.add(Dense(512))\n",
    "model_hidden_layer_4.add(Activation('relu'))\n",
    "model_hidden_layer_4.add(Dropout(0.5))\n",
    "model_hidden_layer_4.add(Dense(512))\n",
    "model_hidden_layer_4.add(Activation('relu'))\n",
    "model_hidden_layer_4.add(Dropout(0.5))\n",
    "model_hidden_layer_4.add(Dense(num_classes))\n",
    "model_hidden_layer_4.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/1945396218.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_hidden_layer_4 = model_hidden_layer_4.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 7s 69ms/step - loss: 2.9362 - accuracy: 0.1578 - val_loss: 1.9408 - val_accuracy: 0.3099\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 2.5037 - accuracy: 0.1916 - val_loss: 1.8835 - val_accuracy: 0.3415\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 2.3936 - accuracy: 0.2074 - val_loss: 1.8598 - val_accuracy: 0.3521\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 7s 67ms/step - loss: 2.3092 - accuracy: 0.2188 - val_loss: 1.9585 - val_accuracy: 0.3066\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 7s 68ms/step - loss: 2.2715 - accuracy: 0.2221 - val_loss: 1.8510 - val_accuracy: 0.3565\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 7s 67ms/step - loss: 2.2346 - accuracy: 0.2287 - val_loss: 1.8398 - val_accuracy: 0.3647\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 2.2051 - accuracy: 0.2330 - val_loss: 1.8548 - val_accuracy: 0.3412\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 7s 67ms/step - loss: 2.1814 - accuracy: 0.2346 - val_loss: 1.8410 - val_accuracy: 0.3502\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 7s 68ms/step - loss: 2.1531 - accuracy: 0.2453 - val_loss: 1.8169 - val_accuracy: 0.3652\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 7s 71ms/step - loss: 2.1405 - accuracy: 0.2449 - val_loss: 1.8366 - val_accuracy: 0.3512\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "model_hidden_layer_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model_hidden_layer_4.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_hidden_layer_4 = model_hidden_layer_4.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.grid() \n",
    "plt.plot(range(epochs),Fit_CNN.history['val_accuracy'],'-or',alpha=0.5,label='CNN') \n",
    "plt.plot(range(epochs),Fit_hidden_layer_0.history['val_accuracy'],'-ob',alpha=0.5,label='DNN0') \n",
    "plt.plot(range(epochs),Fit_hidden_layer_1.history['val_accuracy'],'-og',alpha=0.5,label='DNN1') \n",
    "plt.plot(range(epochs),Fit_hidden_layer_2.history['val_accuracy'],'-oc',alpha=0.5,label='DNN2') \n",
    "plt.plot(range(epochs),Fit_hidden_layer_3.history['val_accuracy'],'-ok',alpha=0.5,label='DNN3') \n",
    "plt.plot(range(epochs),Fit_hidden_layer_4.history['val_accuracy'],'-oy',alpha=0.5,label='DNN4')\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "plt.xlabel('epochs',fontsize=12)\n",
    "plt.ylabel('Accuracy',fontsize=12)\n",
    "_=plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sigmoid activation function\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Conv2D(32, (3, 3), padding='same',\n",
    "    input_shape=x_train.shape[1:]))\n",
    "model_sigmoid.add(Activation('sigmoid'))\n",
    "model_sigmoid.add(Conv2D(32, (3, 3)))\n",
    "model_sigmoid.add(Activation('sigmoid'))\n",
    "model_sigmoid.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_sigmoid.add(Dropout(0.25))\n",
    "\n",
    "model_sigmoid.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_sigmoid.add(Activation('sigmoid'))\n",
    "model_sigmoid.add(Conv2D(64, (3, 3)))\n",
    "model_sigmoid.add(Activation('sigmoid'))\n",
    "model_sigmoid.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_sigmoid.add(Dropout(0.25))\n",
    "\n",
    "model_sigmoid.add(Flatten())\n",
    "model_sigmoid.add(Dense(512))\n",
    "model_sigmoid.add(Activation('sigmoid'))\n",
    "model_sigmoid.add(Dropout(0.5))\n",
    "model_sigmoid.add(Dense(num_classes))\n",
    "model_sigmoid.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/3629456013.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_CNN_sigmoid = model_sigmoid.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 19s 190ms/step - loss: 2.3827 - accuracy: 0.0979 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 19s 189ms/step - loss: 2.3077 - accuracy: 0.0984 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 19s 188ms/step - loss: 2.3045 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 19s 189ms/step - loss: 2.3036 - accuracy: 0.0981 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 19s 188ms/step - loss: 2.3035 - accuracy: 0.0987 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 19s 187ms/step - loss: 2.3034 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 19s 188ms/step - loss: 2.3035 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 19s 187ms/step - loss: 2.3032 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 19s 188ms/step - loss: 2.3032 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 19s 187ms/step - loss: 2.3032 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "model_sigmoid.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model_sigmoid.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_CNN_sigmoid = model_sigmoid.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/2262413454.py:88: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_CNN_d1a1 = modeld1a1.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 18s 182ms/step - loss: 2.1111 - accuracy: 0.2155 - val_loss: 1.9406 - val_accuracy: 0.3154\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 1.9232 - accuracy: 0.3024 - val_loss: 1.7888 - val_accuracy: 0.3824\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 18s 186ms/step - loss: 1.8170 - accuracy: 0.3435 - val_loss: 1.7141 - val_accuracy: 0.3889\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 19s 187ms/step - loss: 1.7503 - accuracy: 0.3686 - val_loss: 1.6256 - val_accuracy: 0.4217\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 18s 186ms/step - loss: 1.7024 - accuracy: 0.3836 - val_loss: 1.5739 - val_accuracy: 0.4362\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 19s 190ms/step - loss: 1.6602 - accuracy: 0.3989 - val_loss: 1.5190 - val_accuracy: 0.4540\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 19s 190ms/step - loss: 1.6235 - accuracy: 0.4111 - val_loss: 1.5138 - val_accuracy: 0.4553\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 18s 186ms/step - loss: 1.5941 - accuracy: 0.4226 - val_loss: 1.4685 - val_accuracy: 0.4719\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 19s 189ms/step - loss: 1.5618 - accuracy: 0.4341 - val_loss: 1.4853 - val_accuracy: 0.4644\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 19s 189ms/step - loss: 1.5428 - accuracy: 0.4412 - val_loss: 1.4877 - val_accuracy: 0.4720\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 18s 186ms/step - loss: 1.5186 - accuracy: 0.4510 - val_loss: 1.4216 - val_accuracy: 0.4866\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 19s 187ms/step - loss: 1.4982 - accuracy: 0.4600 - val_loss: 1.4918 - val_accuracy: 0.4678\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 18s 185ms/step - loss: 1.4827 - accuracy: 0.4648 - val_loss: 1.3480 - val_accuracy: 0.5120\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 18s 183ms/step - loss: 1.4644 - accuracy: 0.4736 - val_loss: 1.3560 - val_accuracy: 0.5104\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 19s 189ms/step - loss: 1.4442 - accuracy: 0.4794 - val_loss: 1.3571 - val_accuracy: 0.5107\n",
      "Epoch 16/100\n",
      "41/98 [===========>..................] - ETA: 9s - loss: 1.4266 - accuracy: 0.4889 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m   datagen\u001b[38;5;241m.\u001b[39mfit(x_train)\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;66;03m# Fit the model on the batches generated by datagen.flow().\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m Fit_CNN_d1a1 \u001b[38;5;241m=\u001b[39m modeld1a1\u001b[38;5;241m.\u001b[39mfit_generator(datagen\u001b[38;5;241m.\u001b[39mflow(x_train, y_train,\n\u001b[1;32m     89\u001b[0m                                  batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[1;32m     90\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     91\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test),\n\u001b[1;32m     92\u001b[0m                     workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m   2811\u001b[0m     generator,\n\u001b[1;32m   2812\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[1;32m   2813\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m   2814\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   2815\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   2816\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[1;32m   2817\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[1;32m   2818\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[1;32m   2819\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[1;32m   2820\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[1;32m   2821\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[1;32m   2822\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[1;32m   2823\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   2824\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[1;32m   2825\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "With drop out and augmentation\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "\n",
    "modeld1a1 = Sequential()\n",
    "modeld1a1.add(Conv2D(32, (3, 3), padding='same',\n",
    "    input_shape=x_train.shape[1:]))\n",
    "modeld1a1.add(Activation('relu'))\n",
    "modeld1a1.add(Conv2D(32, (3, 3)))\n",
    "modeld1a1.add(Activation('relu'))\n",
    "modeld1a1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modeld1a1.add(Dropout(0.25))\n",
    "\n",
    "modeld1a1.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modeld1a1.add(Activation('relu'))\n",
    "modeld1a1.add(Conv2D(64, (3, 3)))\n",
    "modeld1a1.add(Activation('relu'))\n",
    "modeld1a1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modeld1a1.add(Dropout(0.25))\n",
    "\n",
    "modeld1a1.add(Flatten())\n",
    "modeld1a1.add(Dense(512))\n",
    "modeld1a1.add(Activation('relu'))\n",
    "modeld1a1.add(Dropout(0.5))\n",
    "modeld1a1.add(Dense(num_classes))\n",
    "modeld1a1.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "modeld1a1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    modeld1a1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_CNN_d1a1 = modeld1a1.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/lvljp8zs01x6s7xzpqs95b2h0000gn/T/ipykernel_42644/1395830271.py:85: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  Fit_CNN_d0a1 = modeld0a1.fit_generator(datagen.flow(x_train, y_train,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/98 [==>...........................] - ETA: 13s - loss: 2.2568 - accuracy: 0.1605"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m   datagen\u001b[38;5;241m.\u001b[39mfit(x_train)\n\u001b[1;32m     84\u001b[0m   \u001b[38;5;66;03m# Fit the model on the batches generated by datagen.flow().\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m Fit_CNN_d0a1 \u001b[38;5;241m=\u001b[39m modeld0a1\u001b[38;5;241m.\u001b[39mfit_generator(datagen\u001b[38;5;241m.\u001b[39mflow(x_train, y_train,\n\u001b[1;32m     86\u001b[0m                                  batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[1;32m     87\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     88\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test),\n\u001b[1;32m     89\u001b[0m                     workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m   2811\u001b[0m     generator,\n\u001b[1;32m   2812\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[1;32m   2813\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m   2814\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   2815\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   2816\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_data,\n\u001b[1;32m   2817\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[1;32m   2818\u001b[0m     validation_freq\u001b[38;5;241m=\u001b[39mvalidation_freq,\n\u001b[1;32m   2819\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[1;32m   2820\u001b[0m     max_queue_size\u001b[38;5;241m=\u001b[39mmax_queue_size,\n\u001b[1;32m   2821\u001b[0m     workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[1;32m   2822\u001b[0m     use_multiprocessing\u001b[38;5;241m=\u001b[39muse_multiprocessing,\n\u001b[1;32m   2823\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   2824\u001b[0m     initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch,\n\u001b[1;32m   2825\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Without drop out and with augmentation\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "\n",
    "modeld0a1 = Sequential()\n",
    "modeld0a1.add(Conv2D(32, (3, 3), padding='same',\n",
    "    input_shape=x_train.shape[1:]))\n",
    "modeld0a1.add(Activation('relu'))\n",
    "modeld0a1.add(Conv2D(32, (3, 3)))\n",
    "modeld0a1.add(Activation('relu'))\n",
    "modeld0a1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "modeld0a1.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modeld0a1.add(Activation('relu'))\n",
    "modeld0a1.add(Conv2D(64, (3, 3)))\n",
    "modeld0a1.add(Activation('relu'))\n",
    "modeld0a1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "modeld0a1.add(Flatten())\n",
    "modeld0a1.add(Dense(512))\n",
    "modeld0a1.add(Activation('relu'))\n",
    "modeld0a1.add(Dense(num_classes))\n",
    "modeld0a1.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "modeld0a1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    modeld0a1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_CNN_d0a1 = modeld0a1.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "64/98 [==================>...........] - ETA: 5s - loss: 2.2234 - accuracy: 0.1656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_augmentation:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot using data augmentation.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     modeld1a0\u001b[38;5;241m.\u001b[39mfit(x_train, y_train,\n\u001b[1;32m     48\u001b[0m               batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     49\u001b[0m               epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     50\u001b[0m               validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test),\n\u001b[1;32m     51\u001b[0m               shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing real-time data augmentation.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "With drop out and without augmentation\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "\n",
    "modeld1a0 = Sequential()\n",
    "modeld1a0.add(Conv2D(32, (3, 3), padding='same',\n",
    "    input_shape=x_train.shape[1:]))\n",
    "modeld1a0.add(Activation('relu'))\n",
    "modeld1a0.add(Conv2D(32, (3, 3)))\n",
    "modeld1a0.add(Activation('relu'))\n",
    "modeld1a0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modeld1a0.add(Dropout(0.25))\n",
    "\n",
    "modeld1a0.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modeld1a0.add(Activation('relu'))\n",
    "modeld1a0.add(Conv2D(64, (3, 3)))\n",
    "modeld1a0.add(Activation('relu'))\n",
    "modeld1a0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modeld1a0.add(Dropout(0.25))\n",
    "\n",
    "modeld1a0.add(Flatten())\n",
    "modeld1a0.add(Dense(512))\n",
    "modeld1a0.add(Activation('relu'))\n",
    "modeld1a0.add(Dropout(0.5))\n",
    "modeld1a0.add(Dense(num_classes))\n",
    "modeld1a0.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "modeld1a0.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    modeld1a0.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_CNN_d1a0 = modeld1a0.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 16s 159ms/step - loss: 1.9917 - accuracy: 0.2967 - val_loss: 1.8088 - val_accuracy: 0.3654\n",
      "Epoch 2/100\n",
      " 4/98 [>.............................] - ETA: 14s - loss: 1.7657 - accuracy: 0.3745"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_augmentation:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot using data augmentation.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     modeld0a0\u001b[38;5;241m.\u001b[39mfit(x_train, y_train,\n\u001b[1;32m     45\u001b[0m               batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     46\u001b[0m               epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     47\u001b[0m               validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test),\n\u001b[1;32m     48\u001b[0m               shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing real-time data augmentation.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Without drop out and without augmentation\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "\n",
    "modeld0a0 = Sequential()\n",
    "modeld0a0.add(Conv2D(32, (3, 3), padding='same',\n",
    "    input_shape=x_train.shape[1:]))\n",
    "modeld0a0.add(Activation('relu'))\n",
    "modeld0a0.add(Conv2D(32, (3, 3)))\n",
    "modeld0a0.add(Activation('relu'))\n",
    "modeld0a0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "modeld0a0.add(Conv2D(64, (3, 3), padding='same'))\n",
    "modeld0a0.add(Activation('relu'))\n",
    "modeld0a0.add(Conv2D(64, (3, 3)))\n",
    "modeld0a0.add(Activation('relu'))\n",
    "modeld0a0.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "modeld0a0.add(Flatten())\n",
    "modeld0a0.add(Dense(512))\n",
    "modeld0a0.add(Activation('relu'))\n",
    "modeld0a0.add(Dense(num_classes))\n",
    "modeld0a0.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.legacy.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=1e-08, decay=1e-6)\n",
    "\n",
    "modeld0a0.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    modeld0a0.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "  print('Using real-time data augmentation.')\n",
    "  # This will do preprocessing and realtime data augmentation:\n",
    "  datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    zca_epsilon=1e-06, # epsilon for ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0., # set range for random shear\n",
    "    zoom_range=0., # set range for random zoom\n",
    "    channel_shift_range=0., # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0., # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "  # Compute quantities required for feature-wise normalization\n",
    "  # (std, mean, and principal components if ZCA whitening is applied).\n",
    "  datagen.fit(x_train)\n",
    "\n",
    "  # Fit the model on the batches generated by datagen.flow().\n",
    "Fit_CNN_d0a0 = modeld0a0.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.grid() \n",
    "plt.plot(range(epochs),Fit_CNN_d1a1.history['accuracy'],'-or',alpha=0.5,label='with drop & augmentation') \n",
    "plt.plot(range(epochs),Fit_CNN_d0a1.history['accuracy'],'-ob',alpha=0.5,label='w/o drop with augmentation') \n",
    "plt.plot(range(epochs),Fit_CNN_d1a0.history['accuracy'],'-og',alpha=0.5,label='with drop w/o augmentation') \n",
    "plt.plot(range(epochs),Fit_CNN_d0a0.history['accuracy'],'-oc',alpha=0.5,label='w/o drop & augmentation') \n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel('epochs',fontsize=12)\n",
    "plt.ylabel('Training Accuracy',fontsize=12)\n",
    "_=plt.legend(loc='best')\n",
    "\n",
    "\n",
    "plt.grid() \n",
    "plt.plot(range(epochs),Fit_CNN_d1a1.history['val_accuracy'],'-or',alpha=0.5,label='with drop & augmentation') \n",
    "plt.plot(range(epochs),Fit_CNN_d0a1.history['val_accuracy'],'-ob',alpha=0.5,label='w/o drop with augmentation') \n",
    "plt.plot(range(epochs),Fit_CNN_d1a0.history['val_accuracy'],'-og',alpha=0.5,label='with drop w/o augmentation') \n",
    "plt.plot(range(epochs),Fit_CNN_d0a0.history['val_accuracy'],'-oc',alpha=0.5,label='w/o drop & augmentation') \n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel('epochs',fontsize=12)\n",
    "plt.ylabel('Test Accuracy',fontsize=12)\n",
    "_=plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
